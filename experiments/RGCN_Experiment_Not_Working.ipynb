{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNziUzq9nTdU",
        "outputId": "8088af79-a5d8-42ad-a167-27c4cdaff2a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt24cu121)\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt24cpu)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt24cpu)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt24cpu)\n",
            "Requirement already satisfied: pyg-lib in /usr/local/lib/python3.10/dist-packages (0.4.0+pt24cpu)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Requirement already satisfied: pytorch_frame in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_frame) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pytorch_frame) (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_frame) (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_frame) (4.66.6)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from pytorch_frame) (17.0.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from pytorch_frame) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pytorch_frame) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pytorch_frame) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->pytorch_frame) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_frame) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->pytorch_frame) (12.6.77)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->pytorch_frame) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch_frame) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch_frame) (1.3.0)\n",
            "Requirement already satisfied: relbench in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from relbench) (2.2.2)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from relbench) (1.8.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from relbench) (17.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from relbench) (1.26.4)\n",
            "Requirement already satisfied: duckdb in /usr/local/lib/python3.10/dist-packages (from relbench) (1.1.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from relbench) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from relbench) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->relbench) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->relbench) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->relbench) (2024.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->relbench) (4.3.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch->relbench) (24.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch->relbench) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->relbench) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->relbench) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->relbench) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->relbench) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->relbench) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->relbench) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->relbench) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->relbench) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "!pip install torch==2.4.0\n",
        "!pip install torch-geometric torch-sparse torch-scatter torch-cluster torch-spline-conv pyg-lib -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install pytorch_frame\n",
        "!pip install relbench"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IZI63KJokonj",
        "outputId": "4ca2d41e-3620-4209-b3cf-4e819398e3f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.1.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import relbench\n",
        "\n",
        "relbench.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6DWB-Kf6nl2y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
        "from relbench.datasets import get_dataset\n",
        "from relbench.tasks import get_task\n",
        "\n",
        "dataset = get_dataset(\"rel-f1\", download=True)\n",
        "task = get_task(\"rel-f1\", \"driver-position\", download=True)\n",
        "\n",
        "train_table = task.get_table(\"train\")\n",
        "val_table = task.get_table(\"val\")\n",
        "test_table = task.get_table(\"test\")\n",
        "\n",
        "out_channels = 1\n",
        "loss_fn = L1Loss()\n",
        "tune_metric = \"mae\"\n",
        "higher_is_better = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKFT5H51j_Um"
      },
      "source": [
        "Let's check out the training table just to make sure it looks fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABN_fdN3kAB9",
        "outputId": "9109a843-df9a-4aa2-ba85-a3e66c7b74c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Table(df=\n",
              "           date  driverId  position\n",
              "0    2004-07-05        10     10.75\n",
              "1    2004-07-05        47     12.00\n",
              "2    2004-03-07         7     15.00\n",
              "3    2004-01-07        10      9.00\n",
              "4    2003-09-09        52     13.00\n",
              "...         ...       ...       ...\n",
              "7448 1995-08-22        96     15.75\n",
              "7449 1975-06-08       228      8.00\n",
              "7450 1965-05-31       418     16.00\n",
              "7451 1961-08-20       467     37.00\n",
              "7452 1954-05-29       677     30.00\n",
              "\n",
              "[7453 rows x 3 columns],\n",
              "  fkey_col_to_pkey_table={'driverId': 'drivers'},\n",
              "  pkey_col=None,\n",
              "  time_col=date)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQhuHIdHkOxv"
      },
      "source": [
        "Note that to load the data we did not require any deep learning libraries. Now we introduce the PyTorch Frame library, which is useful for encoding individual tables into initial node features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNzfdwsrkPIo",
        "outputId": "3d28fff9-009c-489b-a478-7ee6b71d6b2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torch_frame\n",
        "\n",
        "# Some book keeping\n",
        "from torch_geometric.seed import seed_everything\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)  # check that it's cuda if you want it to run in reasonable time!\n",
        "root_dir = \"./data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y79g5H0kVjX"
      },
      "source": [
        "The first big move is to build a graph out of the database. Here we use our pre-prepared conversion function.\n",
        "\n",
        "The source code can be found at: https://github.com/snap-stanford/relbench/blob/main/relbench/modeling/graph.py\n",
        "\n",
        "Each node in the graph corresonds to a single row in the database. Crucially, PyTorch Frame stores whole tables as objects in a way that is compatibile with PyG minibatch sampling, meaning we can sample subgraphs as in https://arxiv.org/abs/1706.02216, and retrieve the relevant raw features.\n",
        "\n",
        "PyTorch Frame also stores the `stype` (i.e., modality) of each column, and any specialized feature encoders (e.g., text encoders) to be used later. So we need to configure the `stype` for each column, for which we use a function that tries to automatically detect the `stype`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiV3TGI-kRuy",
        "outputId": "1b91bb4f-1b30-4d0a-d42a-c0303b4dc407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Database object from /root/.cache/relbench/rel-f1/db...\n",
            "Done in 0.08 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'qualifying': {'qualifyId': <stype.numerical: 'numerical'>,\n",
              "  'raceId': <stype.numerical: 'numerical'>,\n",
              "  'driverId': <stype.numerical: 'numerical'>,\n",
              "  'constructorId': <stype.numerical: 'numerical'>,\n",
              "  'number': <stype.numerical: 'numerical'>,\n",
              "  'position': <stype.numerical: 'numerical'>,\n",
              "  'date': <stype.timestamp: 'timestamp'>},\n",
              " 'drivers': {'driverId': <stype.numerical: 'numerical'>,\n",
              "  'driverRef': <stype.text_embedded: 'text_embedded'>,\n",
              "  'code': <stype.text_embedded: 'text_embedded'>,\n",
              "  'forename': <stype.text_embedded: 'text_embedded'>,\n",
              "  'surname': <stype.text_embedded: 'text_embedded'>,\n",
              "  'dob': <stype.timestamp: 'timestamp'>,\n",
              "  'nationality': <stype.text_embedded: 'text_embedded'>},\n",
              " 'results': {'resultId': <stype.numerical: 'numerical'>,\n",
              "  'raceId': <stype.numerical: 'numerical'>,\n",
              "  'driverId': <stype.numerical: 'numerical'>,\n",
              "  'constructorId': <stype.numerical: 'numerical'>,\n",
              "  'number': <stype.numerical: 'numerical'>,\n",
              "  'grid': <stype.numerical: 'numerical'>,\n",
              "  'position': <stype.numerical: 'numerical'>,\n",
              "  'positionOrder': <stype.numerical: 'numerical'>,\n",
              "  'points': <stype.numerical: 'numerical'>,\n",
              "  'laps': <stype.numerical: 'numerical'>,\n",
              "  'milliseconds': <stype.numerical: 'numerical'>,\n",
              "  'fastestLap': <stype.numerical: 'numerical'>,\n",
              "  'rank': <stype.numerical: 'numerical'>,\n",
              "  'statusId': <stype.numerical: 'numerical'>,\n",
              "  'date': <stype.timestamp: 'timestamp'>},\n",
              " 'circuits': {'circuitId': <stype.numerical: 'numerical'>,\n",
              "  'circuitRef': <stype.text_embedded: 'text_embedded'>,\n",
              "  'name': <stype.text_embedded: 'text_embedded'>,\n",
              "  'location': <stype.text_embedded: 'text_embedded'>,\n",
              "  'country': <stype.text_embedded: 'text_embedded'>,\n",
              "  'lat': <stype.numerical: 'numerical'>,\n",
              "  'lng': <stype.numerical: 'numerical'>,\n",
              "  'alt': <stype.numerical: 'numerical'>},\n",
              " 'standings': {'driverStandingsId': <stype.numerical: 'numerical'>,\n",
              "  'raceId': <stype.numerical: 'numerical'>,\n",
              "  'driverId': <stype.numerical: 'numerical'>,\n",
              "  'points': <stype.numerical: 'numerical'>,\n",
              "  'position': <stype.numerical: 'numerical'>,\n",
              "  'wins': <stype.numerical: 'numerical'>,\n",
              "  'date': <stype.timestamp: 'timestamp'>},\n",
              " 'constructor_results': {'constructorResultsId': <stype.numerical: 'numerical'>,\n",
              "  'raceId': <stype.numerical: 'numerical'>,\n",
              "  'constructorId': <stype.numerical: 'numerical'>,\n",
              "  'points': <stype.numerical: 'numerical'>,\n",
              "  'date': <stype.timestamp: 'timestamp'>},\n",
              " 'constructor_standings': {'constructorStandingsId': <stype.numerical: 'numerical'>,\n",
              "  'raceId': <stype.numerical: 'numerical'>,\n",
              "  'constructorId': <stype.numerical: 'numerical'>,\n",
              "  'points': <stype.numerical: 'numerical'>,\n",
              "  'position': <stype.numerical: 'numerical'>,\n",
              "  'wins': <stype.numerical: 'numerical'>,\n",
              "  'date': <stype.timestamp: 'timestamp'>},\n",
              " 'races': {'raceId': <stype.numerical: 'numerical'>,\n",
              "  'year': <stype.categorical: 'categorical'>,\n",
              "  'round': <stype.numerical: 'numerical'>,\n",
              "  'circuitId': <stype.numerical: 'numerical'>,\n",
              "  'name': <stype.text_embedded: 'text_embedded'>,\n",
              "  'date': <stype.timestamp: 'timestamp'>,\n",
              "  'time': <stype.timestamp: 'timestamp'>},\n",
              " 'constructors': {'constructorId': <stype.numerical: 'numerical'>,\n",
              "  'constructorRef': <stype.text_embedded: 'text_embedded'>,\n",
              "  'name': <stype.text_embedded: 'text_embedded'>,\n",
              "  'nationality': <stype.text_embedded: 'text_embedded'>}}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from relbench.modeling.utils import get_stype_proposal\n",
        "\n",
        "db = dataset.get_db()\n",
        "col_to_stype_dict = get_stype_proposal(db)\n",
        "col_to_stype_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm3uYXqXkbZt"
      },
      "source": [
        "If trying a new dataset, you should definitely check through this dict of `stype`s to check that look right, and manually change any mistakes by the auto-detection function.\n",
        "\n",
        "Next we also define our text encoding model, which we use GloVe embeddings for speed and convenience. Feel free to try alternatives here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3Dv4sGF0HfK",
        "outputId": "f660eee2-6bc0-400c-cdee-10bd78b6a4ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision==0.19 in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19) (2.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision==0.19) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->torchvision==0.19) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchvision==0.19) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchvision==0.19) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision==0.19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQHYmgIxkX1j",
        "outputId": "99396468-10ba-48ca-c808-5bfafc349bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers # we need another package for text encoding\n",
        "from typing import List, Optional\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class GloveTextEmbedding:\n",
        "    def __init__(self, device: Optional[torch.device\n",
        "                                       ] = None):\n",
        "        self.model = SentenceTransformer(\n",
        "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "    def __call__(self, sentences: List[str]) -> Tensor:\n",
        "        return torch.from_numpy(self.model.encode(sentences))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-BBpUrakdwY",
        "outputId": "5e4d23f8-d4fd-4f3a-f45d-9a50903081a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_frame/utils/io.py:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  tf_dict, col_stats = torch.load(path)\n"
          ]
        }
      ],
      "source": [
        "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "\n",
        "text_embedder_cfg = TextEmbedderConfig(\n",
        "    text_embedder=GloveTextEmbedding(device=device), batch_size=256\n",
        ")\n",
        "\n",
        "data, col_stats_dict = make_pkey_fkey_graph(\n",
        "    db,\n",
        "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
        "    text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
        "    cache_dir=os.path.join(\n",
        "        root_dir, f\"rel-f1_materialized_cache\"\n",
        "    ),  # store materialized graph for convenience\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwQejmg0kzOg"
      },
      "source": [
        "We can now check out `data`, our main graph object. `data` is a heterogeneous and temporal graph, with node types given by the table it originates from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt4a8lw1kufy",
        "outputId": "d8e24520-012e-4bbf-cdfa-f6ce671b2111"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  qualifying={\n",
              "    tf=TensorFrame([4082, 3]),\n",
              "    time=[4082],\n",
              "  },\n",
              "  drivers={ tf=TensorFrame([857, 6]) },\n",
              "  results={\n",
              "    tf=TensorFrame([20323, 11]),\n",
              "    time=[20323],\n",
              "  },\n",
              "  circuits={ tf=TensorFrame([77, 7]) },\n",
              "  standings={\n",
              "    tf=TensorFrame([28115, 4]),\n",
              "    time=[28115],\n",
              "  },\n",
              "  constructor_results={\n",
              "    tf=TensorFrame([9408, 2]),\n",
              "    time=[9408],\n",
              "  },\n",
              "  constructor_standings={\n",
              "    tf=TensorFrame([10170, 4]),\n",
              "    time=[10170],\n",
              "  },\n",
              "  races={\n",
              "    tf=TensorFrame([820, 5]),\n",
              "    time=[820],\n",
              "  },\n",
              "  constructors={ tf=TensorFrame([211, 3]) },\n",
              "  (qualifying, f2p_raceId, races)={ edge_index=[2, 4082] },\n",
              "  (races, rev_f2p_raceId, qualifying)={ edge_index=[2, 4082] },\n",
              "  (qualifying, f2p_driverId, drivers)={ edge_index=[2, 4082] },\n",
              "  (drivers, rev_f2p_driverId, qualifying)={ edge_index=[2, 4082] },\n",
              "  (qualifying, f2p_constructorId, constructors)={ edge_index=[2, 4082] },\n",
              "  (constructors, rev_f2p_constructorId, qualifying)={ edge_index=[2, 4082] },\n",
              "  (results, f2p_raceId, races)={ edge_index=[2, 20323] },\n",
              "  (races, rev_f2p_raceId, results)={ edge_index=[2, 20323] },\n",
              "  (results, f2p_driverId, drivers)={ edge_index=[2, 20323] },\n",
              "  (drivers, rev_f2p_driverId, results)={ edge_index=[2, 20323] },\n",
              "  (results, f2p_constructorId, constructors)={ edge_index=[2, 20323] },\n",
              "  (constructors, rev_f2p_constructorId, results)={ edge_index=[2, 20323] },\n",
              "  (standings, f2p_raceId, races)={ edge_index=[2, 28115] },\n",
              "  (races, rev_f2p_raceId, standings)={ edge_index=[2, 28115] },\n",
              "  (standings, f2p_driverId, drivers)={ edge_index=[2, 28115] },\n",
              "  (drivers, rev_f2p_driverId, standings)={ edge_index=[2, 28115] },\n",
              "  (constructor_results, f2p_raceId, races)={ edge_index=[2, 9408] },\n",
              "  (races, rev_f2p_raceId, constructor_results)={ edge_index=[2, 9408] },\n",
              "  (constructor_results, f2p_constructorId, constructors)={ edge_index=[2, 9408] },\n",
              "  (constructors, rev_f2p_constructorId, constructor_results)={ edge_index=[2, 9408] },\n",
              "  (constructor_standings, f2p_raceId, races)={ edge_index=[2, 10170] },\n",
              "  (races, rev_f2p_raceId, constructor_standings)={ edge_index=[2, 10170] },\n",
              "  (constructor_standings, f2p_constructorId, constructors)={ edge_index=[2, 10170] },\n",
              "  (constructors, rev_f2p_constructorId, constructor_standings)={ edge_index=[2, 10170] },\n",
              "  (races, f2p_circuitId, circuits)={ edge_index=[2, 820] },\n",
              "  (circuits, rev_f2p_circuitId, races)={ edge_index=[2, 820] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd6DqCXgk41x"
      },
      "source": [
        "We can also check out the TensorFrame for one table like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mMQTQeLk1rl",
        "outputId": "e67f5f62-f459-4207-dc99-e1af589d1812"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorFrame(\n",
              "  num_cols=5,\n",
              "  num_rows=820,\n",
              "  categorical (1): ['year'],\n",
              "  numerical (1): ['round'],\n",
              "  timestamp (2): ['date', 'time'],\n",
              "  embedding (1): ['name'],\n",
              "  has_target=False,\n",
              "  device='cpu',\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data[\"races\"].tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kbysKXMk-3X"
      },
      "source": [
        "This may be a little confusing at first, as in graph ML it is more standard to associate to the graph object `data` a tensor, e.g., `data.x` for which `data.x[idx]` is a 1D array/tensor storing all the features for node with index `idx`.\n",
        "\n",
        "But actually this `data` object behaves similarly. For a given node type, e.g., `races` again, `data['races']` stores two pieces of information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDIcp7L5k6pU",
        "outputId": "bb0ef14d-4831-4bf8-c8a9-29127fce28da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tf', 'time']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "list(data[\"races\"].keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z18qPRPllB1H"
      },
      "source": [
        "A `TensorFrame` object, and a timestamp for each node. The `TensorFrame` object acts analogously to the usual tensor of node features, and you can simply use indexing to retrieve the features of a single row (node), or group of nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im8bhNh5lFG6",
        "outputId": "7549892f-4c0b-470a-efca-fa5dc5734858"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorFrame(\n",
              "  num_cols=5,\n",
              "  num_rows=1,\n",
              "  categorical (1): ['year'],\n",
              "  numerical (1): ['round'],\n",
              "  timestamp (2): ['date', 'time'],\n",
              "  embedding (1): ['name'],\n",
              "  has_target=False,\n",
              "  device='cpu',\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data[\"races\"].tf[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYZ28pzNlG4s",
        "outputId": "9c45af9a-c784-4c6e-a458-d353c5860514"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorFrame(\n",
              "  num_cols=5,\n",
              "  num_rows=10,\n",
              "  categorical (1): ['year'],\n",
              "  numerical (1): ['round'],\n",
              "  timestamp (2): ['date', 'time'],\n",
              "  embedding (1): ['name'],\n",
              "  has_target=False,\n",
              "  device='cpu',\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "data[\"races\"].tf[10:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql15svcelK3A"
      },
      "source": [
        "We can also check the edge indices between two different node types, such as `races` amd `circuits`. Note that the edges are also heterogenous, so we also need to specify which edge type we want to look at. Here we look at `f2p_curcuitId`, which are the directed edges pointing _from_ a race (the `f` stands for `foreign key`), _to_ the circuit at which te race happened (the `p` stands for `primary key`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TynkD36QlInL",
        "outputId": "f905de5f-8e6b-416e-a65f-a3b875bf732d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'edge_index': tensor([[  0,   1,   2,  ..., 817, 818, 819],\n",
              "        [  8,   5,  18,  ...,  21,  17,  23]])}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "data[(\"races\", \"f2p_circuitId\", \"circuits\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx4V5KCelNxl"
      },
      "source": [
        "Now we are ready to instantiate our data loaders. For this we will need to import PyTorch Geometric, our GNN library. Whilst we're at it let's add a seed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HUHVG-g6lM-b"
      },
      "outputs": [],
      "source": [
        "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "loader_dict = {}\n",
        "\n",
        "for split, table in [\n",
        "    (\"train\", train_table),\n",
        "    (\"val\", val_table),\n",
        "    (\"test\", test_table),\n",
        "]:\n",
        "    table_input = get_node_train_table_input(\n",
        "        table=table,\n",
        "        task=task,\n",
        "    )\n",
        "    entity_table = table_input.nodes[0]\n",
        "    loader_dict[split] = NeighborLoader(\n",
        "        data,\n",
        "        num_neighbors=[\n",
        "            128 for i in range(2)\n",
        "        ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
        "        time_attr=\"time\",\n",
        "        input_nodes=table_input.nodes,\n",
        "        input_time=table_input.time,\n",
        "        transform=table_input.transform,\n",
        "        batch_size=512,\n",
        "        temporal_strategy=\"uniform\",\n",
        "        shuffle=split == \"train\",\n",
        "        num_workers=0,\n",
        "        persistent_workers=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQc8BWsGludR"
      },
      "source": [
        "Now we need our model...\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple, Union\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import Parameter\n",
        "\n",
        "import torch_geometric.backend\n",
        "import torch_geometric.typing\n",
        "from torch_geometric import is_compiling\n",
        "from torch_geometric.index import index2ptr\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.inits import glorot, zeros\n",
        "from torch_geometric.typing import (\n",
        "    Adj,\n",
        "    OptTensor,\n",
        "    SparseTensor,\n",
        "    pyg_lib,\n",
        "    torch_sparse,\n",
        ")\n",
        "from torch_geometric.utils import index_sort, one_hot, scatter, spmm\n",
        "\n",
        "\n",
        "def masked_edge_index(edge_index: Adj, edge_mask: Tensor) -> Adj:\n",
        "    print(f\"edge_mask shape: {edge_mask.shape}\")\n",
        "    if isinstance(edge_index, Tensor):\n",
        "        return edge_index[:, edge_mask]\n",
        "    return torch_sparse.masked_select_nnz(edge_index, edge_mask, layout='coo')\n",
        "\n",
        "\n",
        "class RGCNConv(MessagePassing):\n",
        "    r\"\"\"The relational graph convolutional operator from the `\"Modeling\n",
        "    Relational Data with Graph Convolutional Networks\"\n",
        "    <https://arxiv.org/abs/1703.06103>`_ paper.\n",
        "\n",
        "    .. math::\n",
        "        \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}_{\\textrm{root}} \\cdot\n",
        "        \\mathbf{x}_i + \\sum_{r \\in \\mathcal{R}} \\sum_{j \\in \\mathcal{N}_r(i)}\n",
        "        \\frac{1}{|\\mathcal{N}_r(i)|} \\mathbf{\\Theta}_r \\cdot \\mathbf{x}_j,\n",
        "\n",
        "    where :math:`\\mathcal{R}` denotes the set of relations, *i.e.* edge types.\n",
        "    Edge type needs to be a one-dimensional :obj:`torch.long` tensor which\n",
        "    stores a relation identifier\n",
        "    :math:`\\in \\{ 0, \\ldots, |\\mathcal{R}| - 1\\}` for each edge.\n",
        "\n",
        "    .. note::\n",
        "        This implementation is as memory-efficient as possible by iterating\n",
        "        over each individual relation type.\n",
        "        Therefore, it may result in low GPU utilization in case the graph has a\n",
        "        large number of relations.\n",
        "        As an alternative approach, :class:`FastRGCNConv` does not iterate over\n",
        "        each individual type, but may consume a large amount of memory to\n",
        "        compensate.\n",
        "        We advise to check out both implementations to see which one fits your\n",
        "        needs.\n",
        "\n",
        "    .. note::\n",
        "        :class:`RGCNConv` can use `dynamic shapes\n",
        "        <https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index\n",
        "        .html#work_dynamic_shapes>`_, which means that the shape of the interim\n",
        "        tensors can be determined at runtime.\n",
        "        If your device doesn't support dynamic shapes, use\n",
        "        :class:`FastRGCNConv` instead.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int or tuple): Size of each input sample. A tuple\n",
        "            corresponds to the sizes of source and target dimensionalities.\n",
        "            In case no input features are given, this argument should\n",
        "            correspond to the number of nodes in your graph.\n",
        "        out_channels (int): Size of each output sample.\n",
        "        num_relations (int): Number of relations.\n",
        "        num_bases (int, optional): If set, this layer will use the\n",
        "            basis-decomposition regularization scheme where :obj:`num_bases`\n",
        "            denotes the number of bases to use. (default: :obj:`None`)\n",
        "        num_blocks (int, optional): If set, this layer will use the\n",
        "            block-diagonal-decomposition regularization scheme where\n",
        "            :obj:`num_blocks` denotes the number of blocks to use.\n",
        "            (default: :obj:`None`)\n",
        "        aggr (str, optional): The aggregation scheme to use\n",
        "            (:obj:`\"add\"`, :obj:`\"mean\"`, :obj:`\"max\"`).\n",
        "            (default: :obj:`\"mean\"`)\n",
        "        root_weight (bool, optional): If set to :obj:`False`, the layer will\n",
        "            not add transformed root node features to the output.\n",
        "            (default: :obj:`True`)\n",
        "        is_sorted (bool, optional): If set to :obj:`True`, assumes that\n",
        "            :obj:`edge_index` is sorted by :obj:`edge_type`. This avoids\n",
        "            internal re-sorting of the data and can improve runtime and memory\n",
        "            efficiency. (default: :obj:`False`)\n",
        "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
        "            an additive bias. (default: :obj:`True`)\n",
        "        **kwargs (optional): Additional arguments of\n",
        "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: Union[int, Tuple[int, int]],\n",
        "        out_channels: int,\n",
        "        num_relations: int,\n",
        "        num_bases: Optional[int] = None,\n",
        "        num_blocks: Optional[int] = None,\n",
        "        aggr: str = 'mean',\n",
        "        root_weight: bool = True,\n",
        "        is_sorted: bool = False,\n",
        "        bias: bool = True,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        kwargs.setdefault('aggr', aggr)\n",
        "        super().__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        if num_bases is not None and num_blocks is not None:\n",
        "            raise ValueError('Can not apply both basis-decomposition and '\n",
        "                             'block-diagonal-decomposition at the same time.')\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.num_relations = num_relations\n",
        "        self.num_bases = num_bases\n",
        "        self.num_blocks = num_blocks\n",
        "        self.is_sorted = is_sorted\n",
        "\n",
        "        if isinstance(in_channels, int):\n",
        "            in_channels = (in_channels, in_channels)\n",
        "        self.in_channels_l = in_channels[0]\n",
        "\n",
        "        self._use_segment_matmul_heuristic_output: torch.jit.Attribute(\n",
        "            None, Optional[float])\n",
        "\n",
        "        if num_bases is not None:\n",
        "            self.weight = Parameter(\n",
        "                torch.empty(num_bases, in_channels[0], out_channels))\n",
        "            self.comp = Parameter(torch.empty(num_relations, num_bases))\n",
        "\n",
        "        elif num_blocks is not None:\n",
        "            assert (in_channels[0] % num_blocks == 0\n",
        "                    and out_channels % num_blocks == 0)\n",
        "            self.weight = Parameter(\n",
        "                torch.empty(num_relations, num_blocks,\n",
        "                            in_channels[0] // num_blocks,\n",
        "                            out_channels // num_blocks))\n",
        "            self.register_parameter('comp', None)\n",
        "\n",
        "        else:\n",
        "            self.weight = Parameter(\n",
        "                torch.empty(num_relations, in_channels[0], out_channels))\n",
        "            self.register_parameter('comp', None)\n",
        "\n",
        "        if root_weight:\n",
        "            self.root = Parameter(torch.empty(in_channels[1], out_channels))\n",
        "        else:\n",
        "            self.register_parameter('root', None)\n",
        "\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.empty(out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        super().reset_parameters()\n",
        "        glorot(self.weight)\n",
        "        glorot(self.comp)\n",
        "        glorot(self.root)\n",
        "        zeros(self.bias)\n",
        "\n",
        "    def forward(self, x: Union[OptTensor, Tuple[OptTensor, Tensor]],\n",
        "                edge_index: Adj, edge_type: OptTensor = None):\n",
        "        r\"\"\"Runs the forward pass of the module.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor or tuple, optional): The input node features.\n",
        "                Can be either a :obj:`[num_nodes, in_channels]` node feature\n",
        "                matrix, or an optional one-dimensional node index tensor (in\n",
        "                which case input features are treated as trainable node\n",
        "                embeddings).\n",
        "                Furthermore, :obj:`x` can be of type :obj:`tuple` denoting\n",
        "                source and destination node features.\n",
        "            edge_index (torch.Tensor or SparseTensor): The edge indices.\n",
        "            edge_type (torch.Tensor, optional): The one-dimensional relation\n",
        "                type/index for each edge in :obj:`edge_index`.\n",
        "                Should be only :obj:`None` in case :obj:`edge_index` is of type\n",
        "                :class:`torch_sparse.SparseTensor`. (default: :obj:`None`)\n",
        "        \"\"\"\n",
        "        # Convert input features to a pair of node features or node indices.\n",
        "        print(\"FORWARD DEBUGGING PRINTS\")\n",
        "        print(f\"x: {x}\")\n",
        "        print(f\"x_l: {x[0].shape}\")\n",
        "        print(f\"x_r: {x[1].shape}\")\n",
        "\n",
        "        x_l: OptTensor = None\n",
        "        if isinstance(x, tuple):\n",
        "            x_l = x[0]\n",
        "        else:\n",
        "            x_l = x\n",
        "        if x_l is None:\n",
        "            x_l = torch.arange(self.in_channels_l, device=self.weight.device)\n",
        "\n",
        "        x_r: Tensor = x_l\n",
        "        if isinstance(x, tuple):\n",
        "            x_r = x[1]\n",
        "\n",
        "        size = (x_l.size(0), x_r.size(0))\n",
        "\n",
        "        # print(f\"edge_index: {edge_index}\")\n",
        "        # print(f\"edge_index.storage.value(): {edge_index.storage.value()}\")\n",
        "        if isinstance(edge_index, SparseTensor):\n",
        "            edge_type = edge_index.storage.value()\n",
        "        assert edge_type is not None\n",
        "\n",
        "        # propagate_type: (x: Tensor, edge_type_ptr: OptTensor)\n",
        "        out = torch.zeros(x_r.size(0), self.out_channels, device=x_r.device)\n",
        "\n",
        "        weight = self.weight\n",
        "        if self.num_bases is not None:  # Basis-decomposition =================\n",
        "            weight = (self.comp @ weight.view(self.num_bases, -1)).view(\n",
        "                self.num_relations, self.in_channels_l, self.out_channels)\n",
        "\n",
        "        if self.num_blocks is not None:  # Block-diagonal-decomposition =====\n",
        "\n",
        "            if not torch.is_floating_point(\n",
        "                    x_r) and self.num_blocks is not None:\n",
        "                raise ValueError('Block-diagonal decomposition not supported '\n",
        "                                 'for non-continuous input features.')\n",
        "\n",
        "            for i in range(self.num_relations):\n",
        "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
        "                h = self.propagate(tmp, x=x_l, edge_type_ptr=None, size=size)\n",
        "                h = h.view(-1, weight.size(1), weight.size(2))\n",
        "                h = torch.einsum('abc,bcd->abd', h, weight[i])\n",
        "                out = out + h.contiguous().view(-1, self.out_channels)\n",
        "\n",
        "        else:  # No regularization/Basis-decomposition ========================\n",
        "\n",
        "            use_segment_matmul = torch_geometric.backend.use_segment_matmul\n",
        "            # If `use_segment_matmul` is not specified, use a simple heuristic\n",
        "            # to determine whether `segment_matmul` can speed up computation\n",
        "            # given the observed input sizes:\n",
        "            if use_segment_matmul is None:\n",
        "                print(f\"edge_index.size{edge_index.size}\")\n",
        "                print(f\"edge_type: {edge_type}, edge_type.shape: {edge_type.shape}\")\n",
        "                segment_count = scatter(torch.ones_like(edge_type), edge_type,\n",
        "                                        dim_size=self.num_relations)\n",
        "\n",
        "                self._use_segment_matmul_heuristic_output = (\n",
        "                    torch_geometric.backend.use_segment_matmul_heuristic(\n",
        "                        num_segments=self.num_relations,\n",
        "                        max_segment_size=int(segment_count.max()),\n",
        "                        in_channels=self.weight.size(1),\n",
        "                        out_channels=self.weight.size(2),\n",
        "                    ))\n",
        "\n",
        "                assert self._use_segment_matmul_heuristic_output is not None\n",
        "                use_segment_matmul = self._use_segment_matmul_heuristic_output\n",
        "\n",
        "            if (use_segment_matmul and torch_geometric.typing.WITH_SEGMM\n",
        "                    and not is_compiling() and self.num_bases is None\n",
        "                    and x_l.is_floating_point()\n",
        "                    and isinstance(edge_index, Tensor)):\n",
        "\n",
        "                if not self.is_sorted:\n",
        "                    if (edge_type[1:] < edge_type[:-1]).any():\n",
        "                        edge_type, perm = index_sort(\n",
        "                            edge_type, max_value=self.num_relations)\n",
        "                        edge_index = edge_index[:, perm]\n",
        "                edge_type_ptr = index2ptr(edge_type, self.num_relations)\n",
        "                out = self.propagate(edge_index, x=x_l,\n",
        "                                     edge_type_ptr=edge_type_ptr, size=size)\n",
        "            else:\n",
        "                for i in range(self.num_relations):\n",
        "                    print(edge_type.shape)\n",
        "                    tmp = masked_edge_index(edge_index, edge_type == i)\n",
        "\n",
        "                    if not torch.is_floating_point(x_r):\n",
        "                        out = out + self.propagate(\n",
        "                            tmp,\n",
        "                            x=weight[i, x_l],\n",
        "                            edge_type_ptr=None,\n",
        "                            size=size,\n",
        "                        )\n",
        "                    else:\n",
        "                        print(f\"out.shape: {out.shape}\")\n",
        "                        print(f\"x_l: {x_l}\")\n",
        "                        print(f\"x_l.shape{x_l.shape}\")\n",
        "                        print(f\"size: {size}\")\n",
        "                        h = self.propagate(tmp, x=x_l, edge_type_ptr=None,\n",
        "                                           size=size)\n",
        "                        print(f\"h.shape{h.shape}\")\n",
        "                        print(f\"weight[i].shape{weight[i].shape}\")\n",
        "                        assert h.shape[0] == size[1]\n",
        "                        out = out + (h @ weight[i])\n",
        "\n",
        "        root = self.root\n",
        "        if root is not None:\n",
        "            if not torch.is_floating_point(x_r):\n",
        "                out = out + root[x_r]\n",
        "            else:\n",
        "                out = out + x_r @ root\n",
        "\n",
        "        if self.bias is not None:\n",
        "            out = out + self.bias\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j: Tensor, edge_type_ptr: OptTensor) -> Tensor:\n",
        "        if (torch_geometric.typing.WITH_SEGMM and not is_compiling()\n",
        "                and edge_type_ptr is not None):\n",
        "            # TODO Re-weight according to edge type degree for `aggr=mean`.\n",
        "            return pyg_lib.ops.segment_matmul(x_j, edge_type_ptr, self.weight)\n",
        "\n",
        "        return x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t: Adj, x: Tensor) -> Tensor:\n",
        "        if isinstance(adj_t, SparseTensor):\n",
        "            adj_t = adj_t.set_value(None)\n",
        "        return spmm(adj_t, x, reduce=self.aggr)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, num_relations={self.num_relations})')"
      ],
      "metadata": {
        "id": "5p6rp71wtYRS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2NsX2AXhENp3"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "import torch\n",
        "import torch_frame\n",
        "from torch import Tensor\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_frame.nn.models import ResNet\n",
        "from torch_geometric.nn import HeteroConv, LayerNorm, PositionalEncoding, SAGEConv, GCNConv\n",
        "from torch_geometric.typing import EdgeType, NodeType\n",
        "from torch_geometric.typing import SparseTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HeteroRGCN(torch.nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      node_types: List[NodeType],\n",
        "      edge_types: List[EdgeType],\n",
        "      channels: int,\n",
        "      aggr: str = \"mean\",\n",
        "      num_layers: int = 2):\n",
        "      super().__init__()\n",
        "\n",
        "      self.edge_types = edge_types\n",
        "      #{relation type A: [first edge with this relation has edge category 0, second edge with this relation has edge category 1, etc.]}\n",
        "      edge_category_set = set()\n",
        "      for edge_type in edge_types:\n",
        "          edge_category_set.add(edge_type[1])\n",
        "      self.edge_category_map = {edge_category: i for i, edge_category in enumerate(edge_category_set)}\n",
        "\n",
        "      self.convs = torch.nn.ModuleList()\n",
        "      for _ in range(num_layers):\n",
        "          conv = HeteroConv(\n",
        "              {\n",
        "                  edge_type: RGCNConv(channels, channels, num_relations=len(edge_types), aggr = aggr)\n",
        "                  for edge_type in edge_types #edge type refers to triplet\n",
        "              },\n",
        "              aggr=\"sum\",  # Aggregation across edge types\n",
        "          )\n",
        "          self.convs.append(conv)\n",
        "\n",
        "      self.norms = torch.nn.ModuleList()\n",
        "      for _ in range(num_layers):\n",
        "          norm_dict = torch.nn.ModuleDict()\n",
        "          for node_type in node_types:\n",
        "              norm_dict[node_type] = LayerNorm(channels, mode=\"node\")\n",
        "          self.norms.append(norm_dict)\n",
        "\n",
        "  def reset_parameters(self):\n",
        "      for conv in self.convs:\n",
        "          conv.reset_parameters()\n",
        "      for norm_dict in self.norms:\n",
        "          for norm in norm_dict.values():\n",
        "              norm.reset_parameters()\n",
        "\n",
        "  def convert_to_sparse(self, edge_index_dict):\n",
        "      for edge_type, edge_index in edge_index_dict.items():\n",
        "          edge_values = torch.ones(edge_index.size(1), device = device).to(torch.int64)\n",
        "          edge_index_dict[edge_type] = SparseTensor(row=edge_index[0].to(torch.int64), col=edge_index[1].to(torch.int64), value = edge_values)\n",
        "\n",
        "  def remove_none_relation_types(self, edge_index_dict):\n",
        "      none_edges = [key for key, value in edge_index_dict.items() if value.size(1) == 0]\n",
        "      for key in none_edges:\n",
        "          del edge_index_dict[key]\n",
        "\n",
        "\n",
        "  def forward(\n",
        "      self,\n",
        "      x_dict: Dict[NodeType, Tensor],\n",
        "      edge_index_dict: Dict[NodeType, Tensor],\n",
        "      num_sampled_nodes_dict: Optional[Dict[NodeType, List[int]]] = None,\n",
        "      num_sampled_edges_dict: Optional[Dict[EdgeType, List[int]]] = None,\n",
        "  ) -> Dict[NodeType, Tensor]:\n",
        "\n",
        "      edge_category_dict = {\n",
        "        edge_type: torch.full(\n",
        "            (edge_index_dict[edge_type].size(1),),  # Use size(1) of the full tensor\n",
        "            self.edge_category_map[edge_type[1]]\n",
        "        )\n",
        "        for edge_type in edge_index_dict.keys()\n",
        "      }\n",
        "      self.remove_none_relation_types(edge_index_dict)\n",
        "      self.convert_to_sparse(edge_index_dict)\n",
        "      print(f\"x_dict size: {x_dict}\")\n",
        "      for _, (conv, norm_dict) in enumerate(zip(self.convs, self.norms)):\n",
        "          x_dict = conv(x_dict, edge_index_dict)\n",
        "          x_dict = {key: norm_dict[key](x) for key, x in x_dict.items()}\n",
        "          x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
        "\n",
        "      return x_dict"
      ],
      "metadata": {
        "id": "vAXgxrN32HZK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "u3m3jEqClQnw"
      },
      "outputs": [],
      "source": [
        "from torch.nn import BCEWithLogitsLoss\n",
        "import copy\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, ModuleDict\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MLP\n",
        "from torch_geometric.typing import NodeType\n",
        "\n",
        "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: HeteroData,\n",
        "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
        "        num_layers: int,\n",
        "        channels: int,\n",
        "        out_channels: int,\n",
        "        aggr: str,\n",
        "        norm: str,\n",
        "        # List of node types to add shallow embeddings to input\n",
        "        shallow_list: List[NodeType] = [],\n",
        "        # ID awareness\n",
        "        id_awareness: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = HeteroEncoder(\n",
        "            channels=channels,\n",
        "            node_to_col_names_dict={\n",
        "                node_type: data[node_type].tf.col_names_dict\n",
        "                for node_type in data.node_types\n",
        "            },\n",
        "            node_to_col_stats=col_stats_dict,\n",
        "        )\n",
        "        self.temporal_encoder = HeteroTemporalEncoder(\n",
        "            node_types=[\n",
        "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
        "            ],\n",
        "            channels=channels,\n",
        "        )\n",
        "        self.gnn = HeteroRGCN(\n",
        "            node_types=data.node_types,\n",
        "            edge_types=data.edge_types,\n",
        "            channels=channels,\n",
        "            aggr=aggr,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.head = MLP(\n",
        "            channels,\n",
        "            out_channels=out_channels,\n",
        "            norm=norm,\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.embedding_dict = ModuleDict(\n",
        "            {\n",
        "                node: Embedding(data.num_nodes_dict[node], channels)\n",
        "                for node in shallow_list\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.id_awareness_emb = None\n",
        "        if id_awareness:\n",
        "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.encoder.reset_parameters()\n",
        "        self.temporal_encoder.reset_parameters()\n",
        "        self.gnn.reset_parameters()\n",
        "        self.head.reset_parameters()\n",
        "        for embedding in self.embedding_dict.values():\n",
        "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
        "        if self.id_awareness_emb is not None:\n",
        "            self.id_awareness_emb.reset_parameters()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[entity_table][: seed_time.size(0)])\n",
        "\n",
        "    def forward_dst_readout(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "        dst_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        if self.id_awareness_emb is None:\n",
        "            raise RuntimeError(\n",
        "                \"id_awareness must be set True to use forward_dst_readout\"\n",
        "            )\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        # Add ID-awareness to the root node\n",
        "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[dst_table])\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=2,\n",
        "    channels=128,\n",
        "    out_channels=1,\n",
        "    aggr=\"sum\",\n",
        "    norm=\"batch_norm\",\n",
        ").to(device)\n",
        "\n",
        "\n",
        "# if you try out different RelBench tasks you will need to change these\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl-6So7Llb-p"
      },
      "source": [
        "We also need standard train/test loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SAHRIr15lVs6"
      },
      "outputs": [],
      "source": [
        "def train() -> float:\n",
        "    model.train()\n",
        "\n",
        "    loss_accum = count_accum = 0\n",
        "    for batch in tqdm(loader_dict[\"train\"]):\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "\n",
        "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_accum += loss.detach().item() * pred.size(0)\n",
        "        count_accum += pred.size(0)\n",
        "\n",
        "    return loss_accum / count_accum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader: NeighborLoader) -> np.ndarray:\n",
        "    model.eval()\n",
        "\n",
        "    pred_list = []\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred_list.append(pred.detach().cpu())\n",
        "    return torch.cat(pred_list, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s-p7dW1ledd"
      },
      "source": [
        "Now we are ready to train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yF3W68Eqlew_",
        "outputId": "d51449d8-ec79-4274-ac7a-31545f0cc894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/15 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_dict size: {'qualifying': tensor([[-0.0507, -0.1374, -0.1300,  ..., -0.9554,  0.3449,  0.0474],\n",
            "        [ 0.0834, -0.0418,  0.2918,  ..., -0.3810, -0.3079,  0.3386],\n",
            "        [ 0.1228,  0.1362,  0.3702,  ..., -0.9824, -0.1003,  0.5063],\n",
            "        ...,\n",
            "        [-0.9434,  0.1796,  0.7265,  ..., -0.8174, -0.5249,  0.5687],\n",
            "        [-0.1571,  0.3097,  0.6933,  ..., -0.4593, -0.0697,  0.3844],\n",
            "        [ 0.0187, -0.0658, -0.1479,  ..., -0.2611,  0.7999,  0.7034]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>), 'drivers': tensor([[-0.6597, -0.7554, -0.9443,  ..., -0.0114, -0.4321,  0.6976],\n",
            "        [-0.1199, -0.5705, -0.5053,  ...,  0.3269,  0.4034, -0.4012],\n",
            "        [ 0.3399, -0.8939, -0.5962,  ..., -0.1072, -0.2863,  0.4295],\n",
            "        ...,\n",
            "        [-0.1507, -0.7998, -0.2184,  ...,  0.3464, -0.0235, -0.3919],\n",
            "        [-0.1319, -0.7740, -0.4964,  ...,  0.2914, -0.3622, -0.2314],\n",
            "        [-0.4548, -0.1001, -0.5029,  ..., -0.4193, -0.3772,  0.6506]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>), 'results': tensor([[ 0.0657, -0.6073, -0.0892,  ...,  0.7593,  0.1613, -0.3031],\n",
            "        [-0.3225, -0.1179, -0.2138,  ..., -0.7428, -0.2292, -1.0685],\n",
            "        [-0.5062,  0.1314, -0.3585,  ..., -0.2074,  0.5949, -1.2738],\n",
            "        ...,\n",
            "        [-0.3935,  0.1177,  0.2768,  ..., -0.0306, -0.2685, -0.3165],\n",
            "        [-0.5297,  0.1007,  0.3735,  ..., -1.1176, -0.3514, -0.6955],\n",
            "        [-1.1584,  0.2670,  0.2895,  ..., -0.3216, -0.2583, -1.2754]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>), 'circuits': tensor([], device='cuda:0', size=(0, 128), grad_fn=<AddmmBackward0>), 'standings': tensor([[ 0.9546, -0.5050,  0.1970,  ..., -0.8319, -0.5664, -0.8203],\n",
            "        [ 0.2757,  0.5425,  0.6421,  ..., -0.2867,  0.3965, -0.2759],\n",
            "        [ 0.0733, -0.1098,  0.1912,  ..., -0.6718, -0.5745, -0.4932],\n",
            "        ...,\n",
            "        [ 0.3792, -0.1943,  0.7171,  ...,  1.0873, -0.3909, -0.1243],\n",
            "        [ 0.9303, -0.7195,  0.0958,  ..., -0.2672, -0.3863, -0.3888],\n",
            "        [ 0.5091, -0.3940,  0.7983,  ...,  0.0146, -0.2464, -0.0541]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>), 'constructor_results': tensor([], device='cuda:0', size=(0, 128), grad_fn=<AddBackward0>), 'constructor_standings': tensor([], device='cuda:0', size=(0, 128), grad_fn=<AddBackward0>), 'races': tensor([[-0.3080, -0.7102, -0.1455,  ..., -0.3104,  0.0162,  0.3273],\n",
            "        [-0.7680, -0.7860,  0.2317,  ...,  0.4718, -0.0861, -0.6788],\n",
            "        [-0.3649, -0.1620,  0.2036,  ..., -0.1799, -0.5043,  1.0926],\n",
            "        ...,\n",
            "        [-0.2929, -0.3668,  0.2126,  ...,  0.6021, -0.0048,  0.7618],\n",
            "        [-0.4661, -0.5352,  0.2732,  ...,  0.1324, -0.3196,  0.4585],\n",
            "        [ 0.0122, -0.8715,  0.3081,  ...,  0.1421,  0.2639,  0.4680]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>), 'constructors': tensor([[ 0.5321, -0.3100,  0.0694,  ...,  0.6485, -0.0984, -0.0582],\n",
            "        [ 0.1658, -0.1040,  0.5551,  ...,  0.5657,  0.6838, -0.0825],\n",
            "        [-0.1901,  0.0855, -0.7365,  ..., -0.1269,  0.7191,  0.3302],\n",
            "        ...,\n",
            "        [-0.2578, -0.7550, -0.7435,  ...,  0.6933, -0.2531,  0.0457],\n",
            "        [-0.2156,  0.5613, -0.1144,  ..., -0.0685,  0.3164, -0.0144],\n",
            "        [ 0.0045, -0.0773, -0.5983,  ...,  0.4378,  0.3692,  0.5839]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)}\n",
            "FORWARD DEBUGGING PRINTS\n",
            "x: (tensor([[-0.3080, -0.7102, -0.1455,  ..., -0.3104,  0.0162,  0.3273],\n",
            "        [-0.7680, -0.7860,  0.2317,  ...,  0.4718, -0.0861, -0.6788],\n",
            "        [-0.3649, -0.1620,  0.2036,  ..., -0.1799, -0.5043,  1.0926],\n",
            "        ...,\n",
            "        [-0.2929, -0.3668,  0.2126,  ...,  0.6021, -0.0048,  0.7618],\n",
            "        [-0.4661, -0.5352,  0.2732,  ...,  0.1324, -0.3196,  0.4585],\n",
            "        [ 0.0122, -0.8715,  0.3081,  ...,  0.1421,  0.2639,  0.4680]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-0.0507, -0.1374, -0.1300,  ..., -0.9554,  0.3449,  0.0474],\n",
            "        [ 0.0834, -0.0418,  0.2918,  ..., -0.3810, -0.3079,  0.3386],\n",
            "        [ 0.1228,  0.1362,  0.3702,  ..., -0.9824, -0.1003,  0.5063],\n",
            "        ...,\n",
            "        [-0.9434,  0.1796,  0.7265,  ..., -0.8174, -0.5249,  0.5687],\n",
            "        [-0.1571,  0.3097,  0.6933,  ..., -0.4593, -0.0697,  0.3844],\n",
            "        [ 0.0187, -0.0658, -0.1479,  ..., -0.2611,  0.7999,  0.7034]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>))\n",
            "x_l: torch.Size([22143, 128])\n",
            "x_r: torch.Size([2317, 128])\n",
            "edge_index.size<bound method SparseTensor.size of SparseTensor(row=tensor([   0,    1,    2,  ..., 2311, 2312, 2313], device='cuda:0'),\n",
            "             col=tensor([   0,    1,    2,  ..., 2314, 2315, 2316], device='cuda:0'),\n",
            "             val=tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0'),\n",
            "             size=(2314, 2317), nnz=2314, density=0.04%)>\n",
            "edge_type: tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0'), edge_type.shape: torch.Size([2314])\n",
            "torch.Size([2314])\n",
            "edge_mask shape: torch.Size([2314])\n",
            "out.shape: torch.Size([2317, 128])\n",
            "x_l: tensor([[-0.3080, -0.7102, -0.1455,  ..., -0.3104,  0.0162,  0.3273],\n",
            "        [-0.7680, -0.7860,  0.2317,  ...,  0.4718, -0.0861, -0.6788],\n",
            "        [-0.3649, -0.1620,  0.2036,  ..., -0.1799, -0.5043,  1.0926],\n",
            "        ...,\n",
            "        [-0.2929, -0.3668,  0.2126,  ...,  0.6021, -0.0048,  0.7618],\n",
            "        [-0.4661, -0.5352,  0.2732,  ...,  0.1324, -0.3196,  0.4585],\n",
            "        [ 0.0122, -0.8715,  0.3081,  ...,  0.1421,  0.2639,  0.4680]],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "x_l.shapetorch.Size([22143, 128])\n",
            "size: (22143, 2317)\n",
            "h.shapetorch.Size([2314, 128])\n",
            "weight[i].shapetorch.Size([128, 128])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-daddfff17f09>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbest_val_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhigher_is_better\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-95e258034628>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         pred = model(\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-bf05d67c85a8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch, entity_table)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mx_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         x_dict = self.gnn(\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-fa8dae536eac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_dict, edge_index_dict, num_sampled_nodes_dict, num_sampled_edges_dict)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"x_dict size: {x_dict}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m           \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m           \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnorm_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m           \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/hetero_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args_dict, **kwargs_dict)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-eb00e8f4f98a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_type)\u001b[0m\n\u001b[1;32m    286\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"h.shape{h.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"weight[i].shape{weight[i].shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                         \u001b[0;32massert\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m                         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "state_dict = None\n",
        "best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train()\n",
        "    val_pred = test(loader_dict[\"val\"])\n",
        "    val_metrics = task.evaluate(val_pred, val_table)\n",
        "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "\n",
        "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "        not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "    ):\n",
        "        best_val_metric = val_metrics[tune_metric]\n",
        "        state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "val_pred = test(loader_dict[\"val\"])\n",
        "val_metrics = task.evaluate(val_pred, val_table)\n",
        "print(f\"Best Val metrics: {val_metrics}\")\n",
        "\n",
        "test_pred = test(loader_dict[\"test\"])\n",
        "test_metrics = task.evaluate(test_pred)\n",
        "print(f\"Best test metrics: {test_metrics}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.version.cuda)\n",
        "print(device)"
      ],
      "metadata": {
        "id": "gtbHQ8kvz31P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58i-5Z508liB"
      },
      "outputs": [],
      "source": [
        "from torch_sparse import SparseTensor\n",
        "\n",
        "# Example SparseTensor creation on CUDA\n",
        "row = torch.tensor([0, 1, 2], device='cuda')\n",
        "col = torch.tensor([1, 2, 0], device='cuda')\n",
        "sparse_tensor = SparseTensor(row=row, col=col)\n",
        "print(sparse_tensor)\n",
        "print(torch_sparse.__version__)  # Ensure the version matches the one you installed"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}